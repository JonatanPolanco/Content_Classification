{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abb730a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b032db91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9323e6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import shutil\n",
    "import sys\n",
    "import tqdm.notebook as tq\n",
    "from collections import defaultdict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c14016f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa4678d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://raw.githubusercontent.com/JonatanPolanco/Content_Classification/main/processed_data.csv'\n",
    "df_data = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93794882",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nombre_contenido</th>\n",
       "      <th>skill_1_definition</th>\n",
       "      <th>Adaptabilidad</th>\n",
       "      <th>Administración de bases de datos</th>\n",
       "      <th>Adquisición del talento</th>\n",
       "      <th>Agilidad de negocios</th>\n",
       "      <th>Alimentación saludable</th>\n",
       "      <th>Analítica de personas</th>\n",
       "      <th>Analítica en marketing</th>\n",
       "      <th>Análisis de datos</th>\n",
       "      <th>...</th>\n",
       "      <th>Tendencias digitales</th>\n",
       "      <th>Toma de decisiones</th>\n",
       "      <th>Trabajo colaborativo</th>\n",
       "      <th>Transformación digital</th>\n",
       "      <th>UX Research</th>\n",
       "      <th>Venta consultiva</th>\n",
       "      <th>Visualización de datos</th>\n",
       "      <th>Vocabulary</th>\n",
       "      <th>Writing</th>\n",
       "      <th>e-Operations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CEO excellence de Dewar, Keller &amp; Malhotra</td>\n",
       "      <td>Habilidad para idear una metodología que busca...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Activa las 3 líneas de defensa de la cibersegu...</td>\n",
       "      <td>Habilidad para emprender acciones preventivas,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Figma: FigJam</td>\n",
       "      <td>Habilidad para usar diferentes herramientas di...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Costos ABC y presupuestos. Herramientas para l...</td>\n",
       "      <td>Habilidad para gestionar y mejorar constanteme...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>La venta humana - José Pascual</td>\n",
       "      <td>Habilidad para asumir el rol de consultor o as...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 155 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    nombre_contenido  \\\n",
       "0         CEO excellence de Dewar, Keller & Malhotra   \n",
       "1  Activa las 3 líneas de defensa de la cibersegu...   \n",
       "2                                      Figma: FigJam   \n",
       "3  Costos ABC y presupuestos. Herramientas para l...   \n",
       "4                    La venta humana - José Pascual   \n",
       "\n",
       "                                  skill_1_definition  Adaptabilidad  \\\n",
       "0  Habilidad para idear una metodología que busca...              0   \n",
       "1  Habilidad para emprender acciones preventivas,...              0   \n",
       "2  Habilidad para usar diferentes herramientas di...              0   \n",
       "3  Habilidad para gestionar y mejorar constanteme...              0   \n",
       "4  Habilidad para asumir el rol de consultor o as...              0   \n",
       "\n",
       "   Administración de bases de datos  Adquisición del talento  \\\n",
       "0                                 0                        0   \n",
       "1                                 0                        0   \n",
       "2                                 0                        0   \n",
       "3                                 0                        0   \n",
       "4                                 0                        0   \n",
       "\n",
       "   Agilidad de negocios  Alimentación saludable  Analítica de personas  \\\n",
       "0                     0                       0                      0   \n",
       "1                     0                       0                      0   \n",
       "2                     0                       0                      0   \n",
       "3                     0                       0                      0   \n",
       "4                     0                       0                      0   \n",
       "\n",
       "   Analítica en marketing  Análisis de datos  ...  Tendencias digitales  \\\n",
       "0                       0                  0  ...                     0   \n",
       "1                       0                  0  ...                     0   \n",
       "2                       0                  0  ...                     0   \n",
       "3                       0                  0  ...                     0   \n",
       "4                       0                  0  ...                     0   \n",
       "\n",
       "   Toma de decisiones  Trabajo colaborativo  Transformación digital  \\\n",
       "0                   0                     0                       0   \n",
       "1                   0                     0                       0   \n",
       "2                   0                     0                       0   \n",
       "3                   0                     0                       0   \n",
       "4                   0                     0                       0   \n",
       "\n",
       "   UX Research  Venta consultiva  Visualización de datos  Vocabulary  Writing  \\\n",
       "0            0                 0                       0           0        0   \n",
       "1            0                 0                       0           0        0   \n",
       "2            0                 0                       0           0        0   \n",
       "3            0                 0                       0           0        0   \n",
       "4            0                 1                       0           0        0   \n",
       "\n",
       "   e-Operations  \n",
       "0             0  \n",
       "1             0  \n",
       "2             0  \n",
       "3             0  \n",
       "4             0  \n",
       "\n",
       "[5 rows x 155 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3377577",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine title and abstract to increase power\n",
    "df_data[\"combined\"] = df_data[\"nombre_contenido\"] + \". \" + df_data[\"skill_1_definition\"]\n",
    "df_data.drop(columns=[\"skill_1_definition\", \"nombre_contenido\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1bbd6d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# split into train and test\n",
    "df_train, df_test = train_test_split(df_data, random_state=77, test_size=0.30, shuffle=True)\n",
    "# split test into test and validation datasets\n",
    "df_test, df_valid = train_test_split(df_test, random_state=88, test_size=0.50, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9fd4d126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (7000, 154), Test: (1500, 154), Valid: (1500, 154)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train: {df_train.shape}, Test: {df_test.shape}, Valid: {df_valid.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "934f4174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "MAX_LEN = 256\n",
    "TRAIN_BATCH_SIZE = 16\n",
    "VALID_BATCH_SIZE = 16\n",
    "TEST_BATCH_SIZE = 16\n",
    "EPOCHS = 300\n",
    "LEARNING_RATE = 1e-05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "69cb408c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8f4c4984",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "96668c3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  2057,  2024,  5604, 14324, 19204, 17629,  1012,   102,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0]])}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the tokenizer\n",
    "test_text = \"We are testing BERT tokenizer.\"\n",
    "# generate encodings\n",
    "encodings = tokenizer.encode_plus(test_text, \n",
    "                                  add_special_tokens = True,\n",
    "                                  max_length = 50,\n",
    "                                  truncation = True,\n",
    "                                  padding = \"max_length\", \n",
    "                                  return_attention_mask = True, \n",
    "                                  return_tensors = \"pt\")\n",
    "# we get a dictionary with three keys (see: https://huggingface.co/transformers/glossary.html) \n",
    "encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e1e60464",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "796     Introducción al Design Thinking. Habilidad par...\n",
       "1047    ¿Cuál es mi NIVEL de DESARROLLADOR?. Habilidad...\n",
       "4742    Conectar MySQL con Django. Habilidad para prog...\n",
       "1065    Realiza demostraciones efectivas en retail. Ha...\n",
       "1954    Criptomonedas más allá de los rumores. Habilid...\n",
       "                              ...                        \n",
       "9119    Arma un equipo excepcional. Habilidad para cla...\n",
       "7832    5 tips para equilibrar vida profesional y pers...\n",
       "9509    Evaluación económica y social de proyectos de ...\n",
       "2283    Toma decisiones conscientes y acertadas. Habil...\n",
       "8799    Matemáticas financieras y evaluación de proyec...\n",
       "Name: combined, Length: 7000, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['combined']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "45d2faa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, tokenizer, max_len, target_list):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.df = df\n",
    "        self.title = list(df['combined'])\n",
    "        self.targets = self.df[target_list].values\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.title)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        title = str(self.title[index])\n",
    "        title = \" \".join(title.split())\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            title,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            padding='max_length',\n",
    "            return_token_type_ids=True,\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        return {\n",
    "            'input_ids': inputs['input_ids'].flatten(),\n",
    "            'attention_mask': inputs['attention_mask'].flatten(),\n",
    "            'token_type_ids': inputs[\"token_type_ids\"].flatten(),\n",
    "            'targets': torch.FloatTensor(self.targets[index]),\n",
    "            'title': title\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "13df674f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Adaptabilidad',\n",
       " 'Administración de bases de datos',\n",
       " 'Adquisición del talento',\n",
       " 'Agilidad de negocios',\n",
       " 'Alimentación saludable',\n",
       " 'Analítica de personas',\n",
       " 'Analítica en marketing',\n",
       " 'Análisis de datos',\n",
       " 'Análisis de escenarios',\n",
       " 'Análisis de estados financieros',\n",
       " 'Análisis económico',\n",
       " 'Aplicaciones Google',\n",
       " 'Aplicaciones Microsoft',\n",
       " 'Aprendizaje continuo',\n",
       " 'Arquitectura TI',\n",
       " 'Asertividad',\n",
       " 'Autocompasión',\n",
       " 'Autoconocimiento',\n",
       " 'Autogestión',\n",
       " 'Automatización de procesos',\n",
       " 'Autorregulación',\n",
       " 'Balance de vida',\n",
       " 'Big data',\n",
       " 'Branding',\n",
       " 'C Sharp (C#)',\n",
       " 'Ciberseguridad',\n",
       " 'Cierre de ventas',\n",
       " 'Coaching de equipos',\n",
       " 'Computadores, dispositivos electrónicos e internet',\n",
       " 'Comunicación efectiva',\n",
       " 'Contenido digital',\n",
       " 'Continuidad del negocio',\n",
       " 'Control de gestión',\n",
       " 'Control de proyectos',\n",
       " 'Control financiero',\n",
       " 'Creatividad',\n",
       " 'Cultura organizacional',\n",
       " 'Customer Relationship Management (CRM)',\n",
       " 'Cómputo en la nube',\n",
       " 'Derecho digital',\n",
       " 'Desarrollo backend',\n",
       " 'Desarrollo del talento',\n",
       " 'Desarrollo frontend',\n",
       " 'Design thinking',\n",
       " 'DevOps',\n",
       " 'Diseño UX',\n",
       " 'Diseño de la experiencia del cliente (CX)',\n",
       " 'Diseño e implementación de APIs',\n",
       " 'Diseño gráfico digital',\n",
       " 'Diversidad, equidad e inclusión',\n",
       " 'Empatía',\n",
       " 'Empoderamiento',\n",
       " 'Estrategia',\n",
       " 'Estrategia digital',\n",
       " 'Experiencia del empleado (EX)',\n",
       " 'Financial services',\n",
       " 'Generación de acuerdos',\n",
       " 'Gestión contable',\n",
       " 'Gestión de calidad',\n",
       " 'Gestión de ciclo de ventas',\n",
       " 'Gestión de la cadena de suministro',\n",
       " 'Gestión de plataformas de e-Commerce',\n",
       " 'Gestión de procesos',\n",
       " 'Gestión de stakeholders',\n",
       " 'Gestión del conflicto',\n",
       " 'Gestión del desempeño',\n",
       " 'Gestión del equipo comercial',\n",
       " 'Gestión del funnel de conversión',\n",
       " 'Gestión del tiempo',\n",
       " 'Gestión documental',\n",
       " 'Gestión legal',\n",
       " 'Google Ads',\n",
       " 'Google Analytics',\n",
       " 'Grammar',\n",
       " 'Growth marketing',\n",
       " 'Hablar en público',\n",
       " 'Herramientas No Code',\n",
       " 'Herramientas colaborativas',\n",
       " 'Herramientas de Amazon',\n",
       " 'Herramientas de desarrollo de software',\n",
       " 'Herramientas de diseño',\n",
       " 'Herramientas de ventas',\n",
       " 'Herramientas para proyectos',\n",
       " 'Hospitality',\n",
       " 'Ideación',\n",
       " 'Inbound marketing',\n",
       " 'Infraestructura tecnológica',\n",
       " 'Integridad',\n",
       " 'Inteligencia artificial (AI)',\n",
       " 'Inteligencia de negocios (BI)',\n",
       " 'Intraemprendimiento',\n",
       " 'Java',\n",
       " 'JavaScript',\n",
       " 'Manejo de objeciones',\n",
       " 'Marca personal',\n",
       " 'Metodologías ágiles',\n",
       " 'Modelos de negocio',\n",
       " 'Motivación',\n",
       " 'NoSQL',\n",
       " 'Organización',\n",
       " 'Orientación a la mejora continua',\n",
       " 'PHP',\n",
       " 'Pensamiento computacional',\n",
       " 'Pensamiento crítico',\n",
       " 'Pensamiento disruptivo',\n",
       " 'Pensamiento estratégico',\n",
       " 'Pensamiento exponencial',\n",
       " 'Pensamiento sistémico',\n",
       " 'Persuasión',\n",
       " 'Planeación de proyectos',\n",
       " 'Planeación financiera',\n",
       " 'Planificación',\n",
       " 'Proactividad',\n",
       " 'Probabilidad y estadística',\n",
       " 'Product marketing',\n",
       " 'Propuesta de valor',\n",
       " 'Prospección',\n",
       " 'Protocolo y etiqueta empresarial',\n",
       " 'Prototipado',\n",
       " 'Python',\n",
       " 'Reading',\n",
       " 'Redacción y ortografía',\n",
       " 'Relacionamiento',\n",
       " 'Relaciones laborales',\n",
       " 'Resiliencia',\n",
       " 'Retail',\n",
       " 'Riesgo financiero y LAFT',\n",
       " 'Riesgo operativo',\n",
       " 'Ruby',\n",
       " 'SQL',\n",
       " 'Salud financiera',\n",
       " 'Salud física',\n",
       " 'Salud mental y emocional',\n",
       " 'Seguridad de la información',\n",
       " 'Seguridad y salud en el trabajo',\n",
       " 'Servicio al cliente',\n",
       " 'Sistema Linux',\n",
       " 'Sistemas de gestión',\n",
       " 'Social media',\n",
       " 'Software testing',\n",
       " 'Sostenibilidad y RSE',\n",
       " 'Storytelling',\n",
       " 'Teletrabajo',\n",
       " 'Tendencias digitales',\n",
       " 'Toma de decisiones',\n",
       " 'Trabajo colaborativo',\n",
       " 'Transformación digital',\n",
       " 'UX Research',\n",
       " 'Venta consultiva',\n",
       " 'Visualización de datos',\n",
       " 'Vocabulary',\n",
       " 'Writing',\n",
       " 'e-Operations',\n",
       " 'combined']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_list = list(df_data.columns)\n",
    "target_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "894ced8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_list = target_list[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bd1e2cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(df_train, tokenizer, MAX_LEN, target_list)\n",
    "valid_dataset = CustomDataset(df_valid, tokenizer, MAX_LEN, target_list)\n",
    "test_dataset = CustomDataset(df_test, tokenizer, MAX_LEN, target_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "331ade27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([  101, 17174,  8566, 14693,  2239,  2632,  2640,  3241,  1012,  5292,\n",
       "         14454, 27893, 11498, 20446, 21335,  2099,  2474, 13675,  5243, 29068,\n",
       "         27893,  1061,  4487,  5054,  2906, 14017, 14194,  3258,  2229, 10861,\n",
       "          1010,  9706, 19341,  8883,  1037,  4895,  4031,  2080,  1051, 14262,\n",
       "          7903,  3695,  1010,  8833,  7389,  2938,  2483, 12172,  2099,  5869,\n",
       "         26785,  2229, 27893,  2229,  2139, 10514,  2149,  6692,  9488,  1010,\n",
       "          1037,  2112,  4313,  3972,  4372,  6528, 22172, 11638,  2080,  7861,\n",
       "         24952,  3597,  2139, 28517,  1061,  3449, 15053, 25101,  9365,  1061,\n",
       "          3231,  8780,  2009,  6906, 29068,  2080,  4372,  4895, 25022, 20464,\n",
       "          2080,  2139,  2033,  5558,  2527,  9530,  7629,  6692,  1012,   102,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'targets': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'title': 'Introducción al Design Thinking. Habilidad para maximizar la creatividad y diseñar soluciones que, aplicadas a un producto o servicio, logren satisfacer las necesidades de su usuario, a partir del entendimiento empático de este y el prototipado y testeo iterativo en un ciclo de mejora contínua.'}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing the dataset\n",
    "next(iter(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "698feb0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loaders\n",
    "train_data_loader = torch.utils.data.DataLoader(train_dataset, \n",
    "    batch_size=TRAIN_BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "val_data_loader = torch.utils.data.DataLoader(valid_dataset, \n",
    "    batch_size=VALID_BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "test_data_loader = torch.utils.data.DataLoader(test_dataset, \n",
    "    batch_size=TEST_BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "72bb9917",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BERTClass(\n",
       "  (bert_model): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (linear): Linear(in_features=768, out_features=153, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class BERTClass(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BERTClass, self).__init__()\n",
    "        self.bert_model = BertModel.from_pretrained('bert-base-uncased', return_dict=True)\n",
    "        self.dropout = torch.nn.Dropout(0.2)\n",
    "        self.linear = torch.nn.Linear(768, 153)\n",
    "    \n",
    "    def forward(self, input_ids, attn_mask, token_type_ids):\n",
    "        output = self.bert_model(\n",
    "            input_ids, \n",
    "            attention_mask=attn_mask, \n",
    "            token_type_ids=token_type_ids\n",
    "        )\n",
    "        output_dropout = self.dropout(output.pooler_output)\n",
    "        output = self.linear(output_dropout)\n",
    "        return output\n",
    "\n",
    "model = BERTClass()\n",
    "\n",
    "# # Freezing BERT layers: (tested, weaker convergence)\n",
    "# for param in model.bert_model.parameters():\n",
    "#     param.requires_grad = False\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ae5a1a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(outputs, targets):\n",
    "    return torch.nn.BCEWithLogitsLoss()(outputs, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d154b503",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\UBITS\\anaconda3\\Lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AdamW\n",
    "\n",
    "# define the optimizer\n",
    "optimizer = AdamW(model.parameters(), lr = 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "044de087",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training of the model for one epoch\n",
    "def train_model(training_loader, model, optimizer):\n",
    "\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "    num_samples = 0\n",
    "    # set model to training mode (activate droput, batch norm)\n",
    "    model.train()\n",
    "    # initialize the progress bar\n",
    "    loop = tq.tqdm(enumerate(training_loader), total=len(training_loader), \n",
    "                      leave=True, colour='steelblue')\n",
    "    for batch_idx, data in loop:\n",
    "        ids = data['input_ids'].to(device, dtype = torch.long)\n",
    "        mask = data['attention_mask'].to(device, dtype = torch.long)\n",
    "        token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
    "        targets = data['targets'].to(device, dtype = torch.float)\n",
    "\n",
    "        # forward\n",
    "        outputs = model(ids, mask, token_type_ids) # (batch,predict)=(32,8)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        losses.append(loss.item())\n",
    "        # training accuracy\n",
    "        _, preds = torch.max(outputs, dim=1) # batch dim \n",
    "        _, targ = torch.max(targets, dim=1)  # batch dim\n",
    "        num_samples += len(targ)  # technically adding batch size\n",
    "        correct_predictions += torch.sum(preds == targ)\n",
    "\n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        # grad descent step\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update progress bar\n",
    "        #loop.set_description(f\"\")\n",
    "        #loop.set_postfix(batch_loss=loss)\n",
    "\n",
    "    # returning: trained model, model accuracy, mean loss\n",
    "    return model, float(correct_predictions)/num_samples, np.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6dcecc30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(validation_loader, model, optimizer):\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "    num_samples = 0\n",
    "    # set model to eval mode (turn off dropout, fix batch norm)\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, data in enumerate(validation_loader, 0):\n",
    "            ids = data['input_ids'].to(device, dtype = torch.long)\n",
    "            mask = data['attention_mask'].to(device, dtype = torch.long)\n",
    "            token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
    "            targets = data['targets'].to(device, dtype = torch.float)\n",
    "            outputs = model(ids, mask, token_type_ids)\n",
    "\n",
    "            loss = loss_fn(outputs, targets)\n",
    "            losses.append(loss.item())\n",
    "\n",
    "            # validation accuracy\n",
    "            _, preds = torch.max(outputs, dim=1) # batch dim \n",
    "            _, targ = torch.max(targets, dim=1)  # batch dim\n",
    "            num_samples += len(targ)  # technically adding batch size\n",
    "            correct_predictions += torch.sum(preds == targ)\n",
    "\n",
    "    return float(correct_predictions)/num_samples, np.mean(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6188b2e4",
   "metadata": {},
   "source": [
    "# Entrenamiento del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3282f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80281c3a06d441b6be7f440df77c898b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/438 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "history = defaultdict(list)\n",
    "best_accuracy = 0\n",
    "\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    print(f'Epoch {epoch}/{EPOCHS}')\n",
    "    model, train_acc, train_loss = train_model(train_data_loader, model, optimizer)\n",
    "    val_acc, val_loss = eval_model(val_data_loader, model, optimizer)\n",
    "\n",
    "    print(f'train_loss={train_loss:.4f}, val_loss={val_loss:.4f} train_acc={train_acc:.4f}, val_acc={val_acc:.4f}')\n",
    "\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['val_acc'].append(val_acc)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    # save the best model\n",
    "    if val_acc > best_accuracy:\n",
    "        torch.save(model.state_dict(), os.path.join(data_dir,\"output\",\"best_model_state.bin\"))\n",
    "        best_accuracy = val_acc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
